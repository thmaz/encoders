{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PI7-3: AE & VAE\n",
    "This notebook contains all the implementation and evaluation of the research performed on autoencoders en variational autoencoders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torchvision\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, z_space: int):\n",
    "        super().__init__()\n",
    "        self.z_space = z_space\n",
    "\n",
    "        # (input)1->64, 64->128, 128->256, 256->z_space\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(256, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.Conv2d(256, z_space, kernel_size=3, stride=2, padding=0, bias=False)\n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        return self.net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__ (self, z_space: int):\n",
    "        super().__init__()\n",
    "        self.z_space = z_space\n",
    "\n",
    "        # z_space->256, 256->128, 128->64, 64->1 \n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_space, 256, kernel_size=4, stride=1, padding=0, bias=False),\n",
    "            nn.BatchNorm2d(256, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(128, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(64, affine=True),\n",
    "            nn.ReLU(inplace=True),\n",
    "\n",
    "            nn.ConvTranspose2d(64, 1, kernel_size=4, stride=2, padding=1, bias=False),\n",
    "        )\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        return self.net(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, z_space: int):\n",
    "        super().__init__()\n",
    "        self.encode = Encoder(z_space)\n",
    "        self.decode = Decoder(z_space)\n",
    "\n",
    "    def forward(self, X: torch.Tensor):\n",
    "        z = self.encode(X)\n",
    "        y = self.decode(z)\n",
    "        \n",
    "        return z, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([64, 20, 1, 1]), torch.Size([64, 1, 32, 32]))"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(64, 1, 32, 32)\n",
    "generator = AutoEncoder(z_space=20)\n",
    "z, y = generator(x)\n",
    "z.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.Resize(32),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "NUM_WORKERS = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 50000\n",
      "Test-Val dataset size: 10000\n",
      "X_test shape: torch.Size([5000, 3, 32, 32]), y_test shape: torch.Size([5000])\n",
      "X_val shape: torch.Size([5000, 3, 32, 32]), y_val shape: torch.Size([5000])\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'data/cifar10_full/train'\n",
    "test_dir = 'data/cifar10_full/test'\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "testval_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "\n",
    "X_test_val, y_test_val = zip(*testval_dataset)\n",
    "\n",
    "X_test_val = torch.stack(X_test_val)\n",
    "y_test_val = torch.tensor(y_test_val)\n",
    "\n",
    "splitval = int(0.5 * len(testval_dataset))\n",
    "\n",
    "test_idx, val_idx = torch.utils.data.random_split(y_test_val, [splitval, splitval])\n",
    "\n",
    "X_test = X_test_val[test_idx.indices]\n",
    "y_test = y_test_val[test_idx.indices]\n",
    "\n",
    "X_val = X_test_val[val_idx.indices]\n",
    "y_val = y_test_val[val_idx.indices]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Test-Val dataset size: {len(testval_dataset)}\")\n",
    "print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
